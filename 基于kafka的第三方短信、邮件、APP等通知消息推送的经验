   项目背景：做的项目是一个物联网项目，涉及到设备告警、服务到期、充值结果反馈、邀请注册、验证码等一系列的第三方消息通知.某天架构师跟我说，要把这个推送服务独立做成一个服务，采用异步方式进行第三方消息
通知.这样，架构师委以重任，让我独立去解决这个问题.
   项目中已经使用kafka 作为消息队列，在MQ选择上使用kafka,这样可以达到异步处理消息的目的.这里我们使用的是spring kafka.
   消息生产者：
      1.首先定义了消息发送结构体，主要包含消息模板ID、具体消息结构体(在消费消息的使用使用了模板消息)、通知方式(短信、邮件、语音、APP、系统消息等)、联系方式(手机号、邮箱、系统中的账号ID);
      2.对不同的消息建立不同的topic,然后根据推送方式发送到对应的topic,分区随机(最初版),不同通知方式的消息互不干扰;消息的发送采用同步的方式，如果没有发送成功，调用方会一直调用直到成功，或者丢到死信队列;
      3.最后将发送消息代码封装为公共的jar,提供给其它微服务引用.
   
       /**
     * 消息模板ID
     */
    private BigInteger id;
    /**
     * 消息模板设置信息
     */
    private SysMsgTemplateSetting setting;
    /**
     * 接收人手机号
     */
    private Set<String> phoneNums;
    /**
     * 接收人邮箱
     */
    private Set<String> emails;
    /**
     * 微信 推送用户ID
     */
    private Set<BigInteger> wechatPushAccountIdList;
    /**
     * APP 推送用户ID
     */
    private Set<BigInteger> appPushAccountIdList;
    /**
     * 通知类型
     */
    private Set<SysMsgNoticeSetting> noticeType;
    /**
     * 系统消息发送人 ,当设置了发送系统消息时必须填写
     */
    private BigInteger from;
    /**
     * 系统消息接收人,当设置了发送系统消息时必须填写
     */
    private List<BigInteger> to;

    /**
     * 消息参数
     */
    @JsonTypeInfo(use=JsonTypeInfo.Id.CLASS, property="@class")
    private BaseTemplateParamModel bean;
    
    
    消息消费者：
        1.采用springboot 构建独立的服务，主要功能包括使用监听kafka 消费消息,接收各厂商APP 推送的通道信息并保存以及模板消息的保存、查询
        2.消费者订阅消息主题，配置适量的线程，对消息进行消费，消费过程主要使用模板引擎格式化消息,然后通过第三方提供的API发送消息，获得消息结果;写消息推送记录(一开始使用的mysql 进行存储);
        3.重试机制，发送失败无限重试
        
        
        
        
        
    推送模型：生产者发送消息---> 根据通知方式发送到对应的topic---> 消费者订阅感兴趣的主题---->消费消息--->写消息推送记录
    
    在这里，我就初步完成了异步消息推送服务的构建.直到有一天，测试提了一个BUG,有一条消息重复发了70多次,第一时间想到是没有去重的原因.然后和同事沟通,他们调用的时候并没有去重，并且还有kafka无限重试
 调用的情况，这意味着调用方可能因为kafka的错误重试无限给我发重复消息.为了降低代码的维护性，架构师和同事们决定去重这个事情全部由消息推送这个环节来处理.
 
    先分析下所需解决的问题：
        1.kafka的错误重试可能会产生重复的消息,而且调用方无法给我提供全局唯一ID;
        
    后面,结合spring kafka的特性，设计出来如下一套去重方案：
        1.重复的消息内容肯定是一致的,在发送消息阶段，将消息体序列化成json 后，采用摘要算法计算摘要,并将该摘要作为kafka发送消息的key，这样能够保证相同的消息负载到同一个分区
        2.消息消费的过程中,将接收到的消息体以同样的摘要算法计算摘要,然后通过布隆过滤器(不懂布隆过滤器知识可以自己了解,我在项目中使用的是redis bitMap)检查是否已经消费过，如果没有消费,直接消费,
          如果已经消费了,再次查询mysql(mysql的设计中使用了覆盖索引,实际测试，推送记录为2000万时效率依然非常高),如果未消费则消费;消费成功后将摘要信息存人布隆过滤器
        3.最后将消费记录写入mysql数据库(消费记录包含消息摘要信息)
        
        
    上述消息去重方案分析：
        1.摘要算法结果字符串长度固定，更加节省空间（PS:在项目中实际有些消息通过摘要算法计算之后为重复的，其实却是不能过滤,我的解决方法是在该消息对象多加一个时间撮属性,并在构造方法中调用赋值系统当前时间）
        2.利用了spring kafka 一个分区只会由一个线程消费消息的特性,避免了多线程的干扰因素,避免加锁等消耗性能的操作
        3.利用了redis 布隆过滤器,海量字符串过滤更省内存空间,效率更高,而且还是天然分布式
        4.利用mysql的覆盖索引,双重检查确保消息不会重复消费
        
 
    推送模型演变为：生产者发送消息---> 根据通知方式及消息体摘要发送到对应的topic中的某个分区(相同的消息会落到同一分区)---> 消息消费者接收消息并生成消息摘要---->通过redis 布隆过滤器和mysql
    顺序检查是否消费 ----> 未消费则消费，已消费丢弃 ---->消费成功摘要信息写入redis bitMap ---> 保存消息记录
    
    
    至此，重复消息的问题得到了解决.
    
    后续又发现还有问题没有得到解决：
        1.消息的重试机制为错误无限重试,其实有些异常一旦发生可能永远无法解决，会无限重试,这样会阻碍后面的消息消费,然后就是会无限地写消息消费失败的记录
        
        
    解决方案：
        1.kafka 的一个分区只会由一个线程消费,项目中采用了错误立即重试的机制,所以我选用了ThreadLocal 对每次消费信息进行记录,记录的信息包括消息摘要,消费次数,消费结果
        2.通过ThreadLocal 记录的信息,无论消息消费成功还是失败,消息记录只会保存一次;如果是重复消息,前面一次消费成功,可以直接丢弃该消息,避免了redis 和Mysql 的IO查询;通过重复消费次数，可以
        自定义自己的处理方式,如放入死信队列、直接丢弃等
 
        
        
     最终推送模型：生产者发送消息---> 根据通知方式及消息体摘要发送到对应的topic中的某个分区(相同的消息会落到同一分区)---> 消息消费者接收消息并生成消息摘要----> 通过ThreadLocal 记录的消息消费
                  信息选择是否丢弃信息,如果丢弃,不再执行后续流程 ---->通过redis 布隆过滤器和mysql顺序检查是否消费 ----> 未消费则消费，已消费丢弃 ---->消费成功摘要信息写入redis bitMap ---> 
                  通过ThreadLocal 记录的消息消费信息选择是否保存推送消息
                  
                  
                  
     到这里，一个较为成熟的推送模型则完成了.总结如下
     
          1.最终推送模型：生产者发送消息---> 根据通知方式及消息体摘要发送到对应的topic中的某个分区(相同的消息会落到同一分区)---> 消息消费者接收消息并生成消息摘要----> 通过ThreadLocal 记录的消息消费
                      信息选择是否丢弃信息,如果丢弃,不再执行后续流程 ---->通过redis 布隆过滤器和mysql顺序检查是否消费 ----> 未消费则消费，已消费丢弃 ---->消费成功摘要信息写入redis bitMap ---> 
                      通过ThreadLocal 记录的消息消费信息选择是否保存推送消息         
          2.充分利用了spring kafka 的特性,设计了串行无锁化的消息消费模型
          
          3.使用了布隆过滤器对海量消息去重
    
    PS:除了上述,后面项目要做国际化,本人用使用了工厂模式加策略模式,使得消息推送服务可以方便的接入和自由地配置第三方服务.在做这个项目中,也是遇到问题解决问题，并不是一步到位设计好,记录下这个经验供以后参考.
    
    
    
